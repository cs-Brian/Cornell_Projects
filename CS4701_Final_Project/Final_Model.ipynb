{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras import models, layers\nfrom sklearn.model_selection import train_test_split\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport os, datetime\n%matplotlib inline \n\n# Global Variables\nRES=128\nNB_CLASSES = 4\nBATCH_SIZE=16\nEPOCHS=100\nOPT = tf.keras.optimizers.RMSprop()\n\n# Evaluate on test dataset helper function\ndef eval_help(model, x_test, y_test):\n    score = model.evaluate(x_test_cn, y_test_cn, batch_size=BATCH_SIZE, verbose=1)\n    print(f\"Test Score: {score[0]}\")\n    print(f\"Test Accuracy: {score[1]}\")\n    return score[1]\n\n# Get images\ndef get_data(directory):\n    x = []\n    y = []\n    mapping={'no_tumor':0, 'pituitary_tumor':1, 'meningioma_tumor':2, 'glioma_tumor':3}\n    count=0\n    for file in os.listdir(directory):\n        path=os.path.join(directory,file)\n        for im in os.listdir(path):\n            image=load_img(os.path.join(path,im), grayscale=True, color_mode=\"grayscale\", target_size=(RES,RES))\n            image=img_to_array(image)\n            image = image/255.0 #normalize\n            x.append(image)\n            y.append(count)  \n        count=count+1\n    return (x,y)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T21:57:01.021308Z","iopub.execute_input":"2022-05-18T21:57:01.021631Z","iopub.status.idle":"2022-05-18T21:57:01.048016Z","shell.execute_reply.started":"2022-05-18T21:57:01.021590Z","shell.execute_reply":"2022-05-18T21:57:01.047091Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Get the training and testing data\n(x_train, y_train) = get_data('/kaggle/input/brain-tumor-classification-mri/Training')\n(x_test, y_test) = get_data('/kaggle/input/brain-tumor-classification-mri/Testing')\n\n# Change to np array\nx_train_cn = np.asarray(x_train).reshape(len(x_train), RES, RES, 1)\nx_test_cn = np.asarray(x_test).reshape(len(x_test), RES, RES, 1)\ny_train_cn = np.asarray(y_train)\ny_test_cn = np.asarray(y_test)\n\n# Change to float32 to increase precision\nx_train_cn = x_train_cn.astype('float32')\nx_test_cn = x_test_cn.astype('float32')\n\n# normalize data\nx_train_cn = x_train_cn / 255.0\nx_test_cn = x_test_cn / 255.0\n\n# One hot encode labels\ny_train_cn = tf.keras.utils.to_categorical(y_train_cn, NB_CLASSES)\ny_test_cn = tf.keras.utils.to_categorical(y_test_cn, NB_CLASSES)\n\n# Shuffle data in training set\n\n# Split training data inot training and validation\nx_train_split, x_validation_split, y_train_split, y_validation_split = train_test_split(x_train_cn, y_train_cn, shuffle=True, random_state=101)\n    # Good idea to check the counts of the classe in training and validation set to see releative balance\n    \n    \n# Create shallow arch\ndef shallow_covnet_arch():\n    model = models.Sequential()\n    model.add(layers.Convolution2D(32, (3,3), activation='relu', input_shape=(RES, RES, 1)))\n    model.add(layers.MaxPooling2D(pool_size=(2,2)))\n    model.add(layers.Dropout(0.2))\n    \n    \n    model.add(layers.Flatten())\n    model.add(layers.Dense(512, activation='relu'))\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Dense(NB_CLASSES, activation='softmax'))\n    return model\n\n\n# Create image data gen\nimggen = ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False, \n        featurewise_std_normalization=False,  \n        samplewise_std_normalization=False,  \n        zca_whitening=False,  \n        rotation_range=0,\n        zoom_range = 0,\n        width_shift_range=0,  \n        height_shift_range=0,  \n        horizontal_flip=True,  \n        vertical_flip=False)\n\n\n# Define early stopper callback so we dont waste time\nes = EarlyStopping(\n    monitor='val_accuracy', \n    mode='max',\n    patience = 3\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T21:51:33.780445Z","iopub.execute_input":"2022-05-18T21:51:33.780840Z","iopub.status.idle":"2022-05-18T21:51:59.356994Z","shell.execute_reply.started":"2022-05-18T21:51:33.780804Z","shell.execute_reply":"2022-05-18T21:51:59.356179Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# fit imggen to x_train_split\nimggen.fit(x_train_split)\n\n# create model\nmodel = shallow_covnet_arch()\n\n# Compile Model\nmodel.compile(optimizer = OPT , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# fit model to imggen on x_train_split and y_train_split\nhistory = model.fit_generator(imggen.flow(x_train_split,y_train_split,batch_size = BATCH_SIZE),\n                              epochs = EPOCHS, validation_data = (x_validation_split,y_validation_split),\n                              steps_per_epoch = x_train_split.shape[0] // BATCH_SIZE,)   ","metadata":{"execution":{"iopub.status.busy":"2022-05-18T21:53:54.143041Z","iopub.execute_input":"2022-05-18T21:53:54.143311Z","iopub.status.idle":"2022-05-18T21:56:08.039903Z","shell.execute_reply.started":"2022-05-18T21:53:54.143281Z","shell.execute_reply":"2022-05-18T21:56:08.039151Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"eval_help(model, x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T21:56:08.053351Z","iopub.execute_input":"2022-05-18T21:56:08.055764Z","iopub.status.idle":"2022-05-18T21:56:08.448797Z","shell.execute_reply.started":"2022-05-18T21:56:08.055721Z","shell.execute_reply":"2022-05-18T21:56:08.448121Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-18T21:57:32.577561Z","iopub.execute_input":"2022-05-18T21:57:32.578035Z","iopub.status.idle":"2022-05-18T21:57:32.586117Z","shell.execute_reply.started":"2022-05-18T21:57:32.577998Z","shell.execute_reply":"2022-05-18T21:57:32.585417Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model.save_weights('52%acc_model.h5', save_format='h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-18T22:00:43.707847Z","iopub.execute_input":"2022-05-18T22:00:43.708220Z","iopub.status.idle":"2022-05-18T22:00:44.421713Z","shell.execute_reply.started":"2022-05-18T22:00:43.708173Z","shell.execute_reply":"2022-05-18T22:00:44.420798Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# fit imggen to x_train_split\nimggen.fit(x_train_split)\n\n# create model\nmodel = shallow_covnet_arch()\n\n# Compile Model\nmodel.compile(optimizer = OPT , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# fit model to imggen on x_train_split and y_train_split\nhistory = model.fit_generator(imggen.flow(x_train_split,y_train_split,batch_size = BATCH_SIZE),\n                              epochs = 100, validation_data = (x_validation_split,y_validation_split),\n                              steps_per_epoch = x_train_split.shape[0] // BATCH_SIZE,)   ","metadata":{"execution":{"iopub.status.busy":"2022-05-18T22:03:40.186410Z","iopub.execute_input":"2022-05-18T22:03:40.186954Z","iopub.status.idle":"2022-05-18T22:08:00.797585Z","shell.execute_reply.started":"2022-05-18T22:03:40.186915Z","shell.execute_reply":"2022-05-18T22:08:00.796863Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"eval_help(model, x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T22:08:03.791413Z","iopub.execute_input":"2022-05-18T22:08:03.791702Z","iopub.status.idle":"2022-05-18T22:08:04.187197Z","shell.execute_reply.started":"2022-05-18T22:08:03.791671Z","shell.execute_reply":"2022-05-18T22:08:04.186443Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model.save_weights('63%acc_model.h5', save_format='h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-18T22:08:22.186898Z","iopub.execute_input":"2022-05-18T22:08:22.187166Z","iopub.status.idle":"2022-05-18T22:08:22.682843Z","shell.execute_reply.started":"2022-05-18T22:08:22.187136Z","shell.execute_reply":"2022-05-18T22:08:22.682101Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# fit imggen to x_train_split\nimggen.fit(x_train_split)\n\n# create model\nmodel = shallow_covnet_arch()\n\n# Compile Model\nmodel.compile(optimizer = OPT , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n# fit model to imggen on x_train_split and y_train_split\nhistory = model.fit_generator(imggen.flow(x_train_split,y_train_split,batch_size = BATCH_SIZE),\n                              epochs = 300, validation_data = (x_validation_split,y_validation_split),\n                              steps_per_epoch = x_train_split.shape[0] // BATCH_SIZE,)   ","metadata":{"execution":{"iopub.status.busy":"2022-05-18T22:08:47.889007Z","iopub.execute_input":"2022-05-18T22:08:47.889274Z","iopub.status.idle":"2022-05-18T22:21:49.724884Z","shell.execute_reply.started":"2022-05-18T22:08:47.889239Z","shell.execute_reply":"2022-05-18T22:21:49.724036Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"eval_help(model, x_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2022-05-18T22:22:08.060932Z","iopub.execute_input":"2022-05-18T22:22:08.061196Z","iopub.status.idle":"2022-05-18T22:22:08.241194Z","shell.execute_reply.started":"2022-05-18T22:22:08.061168Z","shell.execute_reply":"2022-05-18T22:22:08.240498Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}